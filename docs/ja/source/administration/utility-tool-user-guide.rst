==================================
ユーティリティツールユーザーガイド
==================================
この文書では、Asakusa Frameworkが提供するコマンドラインツールの利用方法について解説します。
このコマンドラインツール群を利用することで、運用環境上のメンテナンス作業を軽減します。

すべてのユーティリティツールは、Asakusa Frameworkをインストールしたパスの ``tools/bin`` ディレクトリ内に格納されています。

Hadoopに関するユーティリティ
============================
Hadoopに関するユーティリティツールは、 ``$ASAKUSA_HOME/tools/bin`` ディレクトリ内の ``hadoop-`` から始まるスクリプトとして提供しています。

いずれのツールも ``hadoop`` コマンドを経由して実行するため、環境にHadoopがインストールされている必要があります。
また、Hadoopのインストール先を通知するために、以下の環境変数のいずれかが必要です。

``HADOOP_CMD``
    ``hadoop`` コマンドのパス
``HADOOP_HOME``
    Hadoopのインストール先
``PATH``
    ``hadoop`` コマンドが通っているパス

環境変数の設定方法は、 `コマンドラインツール全体の設定`_ を参照してください。

Hadoopファイルシステムのクリーニング
------------------------------------
``$ASAKUSA_HOME/tools/bin/hadoop-fs-clean.sh`` コマンドを利用すると、Hadoopファイルシステム上の古いファイルやディレクトリを一括して削除できます。

以下の形式で指定します。

..  code-block:: sh

    hadoop-fs-clean.sh -k <days> [-r] [-s] <path> [<path> [...]]

コマンドに指定可能な引数は以下のとおりです。

``-h`` , ``-help``
    ヘルプメッセージを表示して終了します。

``-k <days>`` , ``-keep-days <days>`` (必須)
    最終更新から ``<days>`` 日以上経過したファイルのみを削除します。
    ``0`` を指定した場合には現在時刻よりも古いファイルをすべて削除します。

``-r`` , ``-recursive``
    ディレクトリとその内容を再帰的にクリーニングの対象とします。
    クリーニングによってディレクトリの中身が空になった場合、ディレクトリも削除の対象になります。

``-s`` , ``-dry-run``
    クリーニング時にファイルやディレクトリの削除を行わず、ログだけを出力します。

``<path>`` (必須)
    クリーニング対象のパスをURI形式で指定します。
    2つ以上のパスを指定することもできます。

    ``*`` を含むパスなど、 ``hadoop fs`` コマンドで有効なパス式を指定できます。

``--``
    以降の引数をすべて ``<path>`` とみなします。
    対象のURIが ``-`` から始まる場合などに有効です。


以下は利用例です。

..  code-block:: sh

    # HDFS上の /user/asakusa/var/logs ディレクトリ直下のうち、1日経過したファイルを削除する
    hadoop-fs-clean.sh -k 1 hdfs://localhost:8020/user/asakusa/var/logs/*

    # HDFS上の /user/asakusa/var/logs ディレクトリ内の、10日経過したファイルやディレクトリを再帰的に削除する
    hadoop-fs-clean.sh -k 10 hdfs://localhost:8020/user/asakusa/var/logs/* -r

    # ローカルファイルシステム上の /tmp/hadoop-asakusa ディレクトリに対する全削除をシミュレーションする
    hadoop-fs-clean.sh -dry-run -k 0 file:///tmp/hadoop-asakusa -r

コマンドラインツール全体の設定
==============================
上記で紹介したコマンドラインツールは、実行前に ``$ASAKUSA_HOME/tools/env.sh`` を読み込んで必要な環境変数の設定などを行います。

以下は同ファイルの内容を改変し、環境変数 ``HADOOP_HOME`` を設定する例です。

..  code-block:: sh

    export HADOOP_HOME=/usr/lib/hadoop


